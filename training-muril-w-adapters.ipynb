{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12078455,"sourceType":"datasetVersion","datasetId":7603345},{"sourceId":12078472,"sourceType":"datasetVersion","datasetId":7603360},{"sourceId":12116847,"sourceType":"datasetVersion","datasetId":7629200},{"sourceId":431255,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":351533,"modelId":372783},{"sourceId":431257,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":351534,"modelId":372784}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Import necessary libraries","metadata":{}},{"cell_type":"code","source":"import torch\n\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, get_cosine_with_hard_restarts_schedule_with_warmup, Trainer, TrainingArguments, EarlyStoppingCallback\nfrom torch.optim import AdamW\nimport pandas as pd\nfrom torch.utils.data import random_split, DataLoader, RandomSampler, SequentialSampler, Dataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import compute_class_weight\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom peft import get_peft_model, LoraConfig, PeftModelForSequenceClassification\nimport torch.nn as nn\n\nimport tqdm as notebook_tqdm\n\nimport numpy as np\nimport time\nimport datetime\nimport random\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import font_manager\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:29:48.124332Z","iopub.execute_input":"2025-06-11T06:29:48.124539Z","iopub.status.idle":"2025-06-11T06:30:14.862300Z","shell.execute_reply.started":"2025-06-11T06:29:48.124522Z","shell.execute_reply":"2025-06-11T06:30:14.861508Z"}},"outputs":[{"name":"stderr","text":"2025-06-11 06:30:01.568756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749623401.738345      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749623401.787659      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Set device to CUDA","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\ntorch.manual_seed(42)\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:30:42.073196Z","iopub.execute_input":"2025-06-11T06:30:42.074187Z","iopub.status.idle":"2025-06-11T06:30:42.086106Z","shell.execute_reply.started":"2025-06-11T06:30:42.074152Z","shell.execute_reply":"2025-06-11T06:30:42.085103Z"}},"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Get model and tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = 'google/muril-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:30:44.959994Z","iopub.execute_input":"2025-06-11T06:30:44.960357Z","iopub.status.idle":"2025-06-11T06:30:47.571566Z","shell.execute_reply.started":"2025-06-11T06:30:44.960326Z","shell.execute_reply":"2025-06-11T06:30:47.570661Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e1740427404dd1903b76537b54c9a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7f4ccff9874568b9a6b1a269eafead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4bf642fb4744e28d364e36ea21a70e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbd4a12e85404d8fac9693719384c1b4"}},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"### Prepare Data","metadata":{}},{"cell_type":"markdown","source":"- Load Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/hate-dataset-train/hate-dataset-train.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:30:49.800818Z","iopub.execute_input":"2025-06-11T06:30:49.801132Z","iopub.status.idle":"2025-06-11T06:30:50.010044Z","shell.execute_reply.started":"2025-06-11T06:30:49.801111Z","shell.execute_reply":"2025-06-11T06:30:50.009317Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                data     label\n0            an extremist hindu crying for no reason      hate\n1       हमारे मूर्धन्य हमारा खुदा हैं एक hi होता हैं  non-hate\n2  इसमें देखो कौन पैसे के लिए दौड़ता he हिन्दू एक...  non-hate\n3      वही नारा अब हम लोगों को भी follow करना पड़ेगा  non-hate\n4  तुम जैसे कुछ बूंद लोगों की वजह se सबकी pakista...  non-hate","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>data</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>an extremist hindu crying for no reason</td>\n      <td>hate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>हमारे मूर्धन्य हमारा खुदा हैं एक hi होता हैं</td>\n      <td>non-hate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>इसमें देखो कौन पैसे के लिए दौड़ता he हिन्दू एक...</td>\n      <td>non-hate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>वही नारा अब हम लोगों को भी follow करना पड़ेगा</td>\n      <td>non-hate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>तुम जैसे कुछ बूंद लोगों की वजह se सबकी pakista...</td>\n      <td>non-hate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"- Tokenize Data for MuRIL","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.tokenizer = tokenizer\n        self.texts = texts\n        self.labels = self.encode_labels(labels)\n        self.max_length = max_length\n\n    def encode_labels(self, y):\n        encoder = LabelEncoder()\n        encoder.fit(y)\n        y_encoded = encoder.transform(y)\n        self.label_encoder = encoder  # save encoder for inverse_transform if needed\n        print(f\"Encoder has the following classes: {encoder.classes_}\")\n        print(f\"The new data type for y is {type(y_encoded)}\")\n        return y_encoded\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        input_ids = encoding['input_ids'].squeeze(0)         # remove batch dim\n        attention_mask = encoding['attention_mask'].squeeze(0)\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Usage\nX = df.data.values\ny = df.label.values\n\ndataset = MyDataset(X, y, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:30:55.643015Z","iopub.execute_input":"2025-06-11T06:30:55.643532Z","iopub.status.idle":"2025-06-11T06:30:55.656266Z","shell.execute_reply.started":"2025-06-11T06:30:55.643510Z","shell.execute_reply":"2025-06-11T06:30:55.655556Z"}},"outputs":[{"name":"stdout","text":"Encoder has the following classes: ['hate' 'non-hate']\nThe new data type for y is <class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"- Assign Class Weights","metadata":{}},{"cell_type":"code","source":"labels_class = df['label']\nprint(np.unique(labels_class))\nclass_weights = compute_class_weight(\"balanced\", classes=np.unique(labels_class), y=labels_class)\n\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nclass_weights = class_weights.to(device)\nclass_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:30:58.871001Z","iopub.execute_input":"2025-06-11T06:30:58.871278Z","iopub.status.idle":"2025-06-11T06:30:59.347989Z","shell.execute_reply.started":"2025-06-11T06:30:58.871258Z","shell.execute_reply":"2025-06-11T06:30:59.347242Z"}},"outputs":[{"name":"stdout","text":"['hate' 'non-hate']\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"tensor([1.2938, 0.8150], device='cuda:0')"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"- Split into Train and Eval","metadata":{}},{"cell_type":"code","source":"train_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint(f\"{train_size} training samples\")\nprint(f\"{val_size} validation samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:31:02.052105Z","iopub.execute_input":"2025-06-11T06:31:02.052824Z","iopub.status.idle":"2025-06-11T06:31:02.060081Z","shell.execute_reply.started":"2025-06-11T06:31:02.052800Z","shell.execute_reply":"2025-06-11T06:31:02.059356Z"}},"outputs":[{"name":"stdout","text":"24230 training samples\n2693 validation samples\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"markdown","source":"- Set metrics","metadata":{}},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n\n    # Calculate accuracy\n    accuracy = accuracy_score(labels, preds)\n\n   # Calculate precision, recall, and F1-score\n    precision = precision_score(labels, preds, average='weighted', zero_division=1)\n    recall = recall_score(labels, preds, average='weighted', zero_division=1)\n    f1 = f1_score(labels, preds, average='weighted', zero_division=1)\n\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:31:04.328882Z","iopub.execute_input":"2025-06-11T06:31:04.329554Z","iopub.status.idle":"2025-06-11T06:31:04.333999Z","shell.execute_reply.started":"2025-06-11T06:31:04.329525Z","shell.execute_reply":"2025-06-11T06:31:04.333385Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"- Load Model and LoRA","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels = 2,\n        output_attentions = False,\n        output_hidden_states = False,\n)\n\nfor name, param in model.named_parameters():\n\tif 'classifier' not in name: # classifier layer\n\t\tparam.requires_grad = False\n\nloraConfig = LoraConfig(task_type=\"SEQ_CLS\",\n                         inference_mode=False,\n                         lora_alpha=128,\n                         lora_dropout=0.1,\n                         r=128,\n                         use_rslora=True)\n\nmodel = get_peft_model(model, loraConfig, adapter_name='hinglish_hate_1')\nmodel.add_adapter(\"hinglish_hate_2\", loraConfig)\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:01:30.298402Z","iopub.execute_input":"2025-06-11T07:01:30.298995Z","iopub.status.idle":"2025-06-11T07:01:32.494054Z","shell.execute_reply.started":"2025-06-11T07:01:30.298974Z","shell.execute_reply":"2025-06-11T07:01:32.493446Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): BertForSequenceClassification(\n      (bert): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(197285, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0-11): 12 x BertLayer(\n              (attention): BertAttention(\n                (self): BertSdpaSelfAttention(\n                  (query): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (hinglish_hate_1): Dropout(p=0.1, inplace=False)\n                      (hinglish_hate_2): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (hinglish_hate_1): Linear(in_features=768, out_features=128, bias=False)\n                      (hinglish_hate_2): Linear(in_features=768, out_features=128, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (hinglish_hate_1): Linear(in_features=128, out_features=768, bias=False)\n                      (hinglish_hate_2): Linear(in_features=128, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (hinglish_hate_1): Dropout(p=0.1, inplace=False)\n                      (hinglish_hate_2): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (hinglish_hate_1): Linear(in_features=768, out_features=128, bias=False)\n                      (hinglish_hate_2): Linear(in_features=768, out_features=128, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (hinglish_hate_1): Linear(in_features=128, out_features=768, bias=False)\n                      (hinglish_hate_2): Linear(in_features=128, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (pooler): BertPooler(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (activation): Tanh()\n        )\n      )\n      (dropout): Dropout(p=0.1, inplace=False)\n      (classifier): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=768, out_features=2, bias=True)\n        (modules_to_save): ModuleDict(\n          (hinglish_hate_1): Linear(in_features=768, out_features=2, bias=True)\n          (hinglish_hate_2): Linear(in_features=768, out_features=2, bias=True)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"- Set Hyperparameters","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nepochs = 20\nlearning_rate = 2e-5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:01:37.603423Z","iopub.execute_input":"2025-06-11T07:01:37.603692Z","iopub.status.idle":"2025-06-11T07:01:37.607334Z","shell.execute_reply.started":"2025-06-11T07:01:37.603673Z","shell.execute_reply":"2025-06-11T07:01:37.606683Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"- Create custom loss func, optimizer, scheduler and training arguments","metadata":{}},{"cell_type":"code","source":"class ClassificationTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=batch_size):\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.get('logits')\n        loss_fct = nn.CrossEntropyLoss(weight=class_weights, reduction='mean')\n        loss = loss_fct(logits, labels)\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:01:39.586509Z","iopub.execute_input":"2025-06-11T07:01:39.586778Z","iopub.status.idle":"2025-06-11T07:01:39.591705Z","shell.execute_reply.started":"2025-06-11T07:01:39.586759Z","shell.execute_reply":"2025-06-11T07:01:39.590906Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                lr = learning_rate,\n                )\n\n\nscheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=(len(train_dataset) // batch_size) * epochs\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results/adapter_1\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=epochs,\n    logging_dir=\"/kaggle/working/logs/adapter_2\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    report_to=\"none\",\n    label_names=[\"labels\"]\n)\n\n\ntrainer = ClassificationTrainer(\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    optimizers=(optimizer, scheduler),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:01:41.886815Z","iopub.execute_input":"2025-06-11T07:01:41.887576Z","iopub.status.idle":"2025-06-11T07:01:41.925668Z","shell.execute_reply.started":"2025-06-11T07:01:41.887552Z","shell.execute_reply":"2025-06-11T07:01:41.924958Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"- Start training","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:01:45.402672Z","iopub.execute_input":"2025-06-11T07:01:45.403396Z","iopub.status.idle":"2025-06-11T07:56:42.675246Z","shell.execute_reply.started":"2025-06-11T07:01:45.403372Z","shell.execute_reply":"2025-06-11T07:56:42.674540Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10612' max='15160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10612/15160 54:56 < 23:33, 3.22 it/s, Epoch 14/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.685000</td>\n      <td>0.669378</td>\n      <td>0.686595</td>\n      <td>0.685879</td>\n      <td>0.686595</td>\n      <td>0.665622</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.653500</td>\n      <td>0.648435</td>\n      <td>0.711474</td>\n      <td>0.712985</td>\n      <td>0.711474</td>\n      <td>0.695311</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.638500</td>\n      <td>0.629063</td>\n      <td>0.725214</td>\n      <td>0.723761</td>\n      <td>0.725214</td>\n      <td>0.715141</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.611700</td>\n      <td>0.608280</td>\n      <td>0.740438</td>\n      <td>0.737669</td>\n      <td>0.740438</td>\n      <td>0.735103</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.595000</td>\n      <td>0.596281</td>\n      <td>0.731155</td>\n      <td>0.729766</td>\n      <td>0.731155</td>\n      <td>0.730313</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.575200</td>\n      <td>0.588934</td>\n      <td>0.742666</td>\n      <td>0.739746</td>\n      <td>0.742666</td>\n      <td>0.739318</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.562100</td>\n      <td>0.577018</td>\n      <td>0.733754</td>\n      <td>0.734131</td>\n      <td>0.733754</td>\n      <td>0.733934</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.543400</td>\n      <td>0.575028</td>\n      <td>0.723357</td>\n      <td>0.734131</td>\n      <td>0.723357</td>\n      <td>0.725776</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.534300</td>\n      <td>0.566638</td>\n      <td>0.746008</td>\n      <td>0.744778</td>\n      <td>0.746008</td>\n      <td>0.745257</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.515800</td>\n      <td>0.565328</td>\n      <td>0.741552</td>\n      <td>0.744161</td>\n      <td>0.741552</td>\n      <td>0.742535</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.509600</td>\n      <td>0.560934</td>\n      <td>0.744152</td>\n      <td>0.747123</td>\n      <td>0.744152</td>\n      <td>0.745229</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.496900</td>\n      <td>0.561310</td>\n      <td>0.744152</td>\n      <td>0.745488</td>\n      <td>0.744152</td>\n      <td>0.744720</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.490600</td>\n      <td>0.561908</td>\n      <td>0.747494</td>\n      <td>0.746773</td>\n      <td>0.747494</td>\n      <td>0.747091</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.483500</td>\n      <td>0.566337</td>\n      <td>0.746008</td>\n      <td>0.744496</td>\n      <td>0.746008</td>\n      <td>0.745030</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Could not locate the best model at /kaggle/working/results/adapter_1/checkpoint-8338/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=10612, training_loss=0.5627552241682332, metrics={'train_runtime': 3296.7921, 'train_samples_per_second': 146.991, 'train_steps_per_second': 4.598, 'total_flos': 2.47725186476544e+16, 'train_loss': 0.5627552241682332, 'epoch': 14.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"markdown","source":"- Load and prepare Test Data","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/hinglish-hate/test-task1.csv\")\nX = test_df.data.values\ny = test_df.label.values\ntest_dataset = MyDataset(X, y, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:59:01.834747Z","iopub.execute_input":"2025-06-11T07:59:01.835049Z","iopub.status.idle":"2025-06-11T07:59:01.867095Z","shell.execute_reply.started":"2025-06-11T07:59:01.835028Z","shell.execute_reply":"2025-06-11T07:59:01.866381Z"}},"outputs":[{"name":"stdout","text":"Encoder has the following classes: ['hate' 'non-hate']\nThe new data type for y is <class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"- Predict and evaluate accuracy","metadata":{}},{"cell_type":"code","source":"trainer.predict(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:59:04.124224Z","iopub.execute_input":"2025-06-11T07:59:04.124497Z","iopub.status.idle":"2025-06-11T07:59:09.652122Z","shell.execute_reply.started":"2025-06-11T07:59:04.124480Z","shell.execute_reply":"2025-06-11T07:59:09.651347Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[-0.5519283 ,  0.57854617],\n       [ 0.45793357, -0.43980888],\n       [-0.5446111 ,  0.5731474 ],\n       ...,\n       [-0.55422044,  0.5816745 ],\n       [ 0.66868454, -0.65999323],\n       [ 0.6703883 , -0.66175264]], dtype=float32), label_ids=array([1, 0, 1, ..., 1, 0, 0]), metrics={'test_loss': 0.5722740888595581, 'test_accuracy': 0.7424135497529993, 'test_precision': 0.7467601580238625, 'test_recall': 0.7424135497529993, 'test_f1': 0.7441305872034747, 'test_runtime': 5.5188, 'test_samples_per_second': 256.76, 'test_steps_per_second': 8.154})"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"- Save LoRA Adapter","metadata":{}},{"cell_type":"code","source":"output_dir = \"/kaggle/working/hinglish_hate_1/\"\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:01:02.112155Z","iopub.execute_input":"2025-06-09T09:01:02.112699Z","iopub.status.idle":"2025-06-09T09:01:02.496925Z","shell.execute_reply.started":"2025-06-09T09:01:02.112679Z","shell.execute_reply":"2025-06-09T09:01:02.496342Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### (Optional) Resume Training","metadata":{}},{"cell_type":"code","source":"trainer.train(resume_from_checkpoint=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T09:03:32.092161Z","iopub.execute_input":"2025-06-09T09:03:32.092944Z","iopub.status.idle":"2025-06-09T09:15:16.917230Z","shell.execute_reply.started":"2025-06-09T09:03:32.092920Z","shell.execute_reply":"2025-06-09T09:15:16.916518Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Continual Learning","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/hinglish-hate-task-2/cont_train.csv\")\n\nX = df.data.values\ny = df.label.values\n\ndataset = MyDataset(X, y, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:59:24.157297Z","iopub.execute_input":"2025-06-11T07:59:24.157773Z","iopub.status.idle":"2025-06-11T07:59:24.207446Z","shell.execute_reply.started":"2025-06-11T07:59:24.157751Z","shell.execute_reply":"2025-06-11T07:59:24.206882Z"}},"outputs":[{"name":"stdout","text":"Encoder has the following classes: ['hate' 'non-hate']\nThe new data type for y is <class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint(f\"{train_size} training samples\")\nprint(f\"{val_size} validation samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:59:27.016105Z","iopub.execute_input":"2025-06-11T07:59:27.016775Z","iopub.status.idle":"2025-06-11T07:59:27.021673Z","shell.execute_reply.started":"2025-06-11T07:59:27.016756Z","shell.execute_reply":"2025-06-11T07:59:27.020953Z"}},"outputs":[{"name":"stdout","text":"4325 training samples\n481 validation samples\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"labels_class = df['label']\nprint(np.unique(labels_class))\nclass_weights = compute_class_weight(\"balanced\", classes=np.unique(labels_class), y=labels_class)\n\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nclass_weights = class_weights.to(device)\nclass_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:59:29.207589Z","iopub.execute_input":"2025-06-11T07:59:29.208267Z","iopub.status.idle":"2025-06-11T07:59:29.221196Z","shell.execute_reply.started":"2025-06-11T07:59:29.208247Z","shell.execute_reply":"2025-06-11T07:59:29.220555Z"}},"outputs":[{"name":"stdout","text":"['hate' 'non-hate']\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"tensor([1.1492, 0.8851], device='cuda:0')"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"model.set_adapter(\"hinglish_hate_2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:59:58.232559Z","iopub.execute_input":"2025-06-11T07:59:58.233114Z","iopub.status.idle":"2025-06-11T07:59:58.238661Z","shell.execute_reply.started":"2025-06-11T07:59:58.233092Z","shell.execute_reply":"2025-06-11T07:59:58.237891Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"batch_size = 32\nepochs = 20\nlearning_rate = 2e-5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:00:04.365822Z","iopub.execute_input":"2025-06-11T08:00:04.366662Z","iopub.status.idle":"2025-06-11T08:00:04.370237Z","shell.execute_reply.started":"2025-06-11T08:00:04.366637Z","shell.execute_reply":"2025-06-11T08:00:04.369428Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                lr = learning_rate,\n                )\n\n\nscheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=(len(train_dataset) // batch_size) * epochs\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results/adapter_2\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_steps=100,\n    save_total_limit=1,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=epochs,\n    logging_dir=\"/kaggle/working/logs/adapter_2\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    report_to=\"none\",\n    label_names=[\"labels\"]\n)\n\n\ntrainer = ClassificationTrainer(\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    optimizers=(optimizer, scheduler),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:00:25.059518Z","iopub.execute_input":"2025-06-11T08:00:25.059992Z","iopub.status.idle":"2025-06-11T08:00:25.099228Z","shell.execute_reply.started":"2025-06-11T08:00:25.059970Z","shell.execute_reply":"2025-06-11T08:00:25.098347Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:00:29.307122Z","iopub.execute_input":"2025-06-11T08:00:29.307644Z","iopub.status.idle":"2025-06-11T08:14:43.704014Z","shell.execute_reply.started":"2025-06-11T08:00:29.307626Z","shell.execute_reply":"2025-06-11T08:14:43.703409Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2720' max='2720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2720/2720 14:13, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.692200</td>\n      <td>0.677835</td>\n      <td>0.677755</td>\n      <td>0.736023</td>\n      <td>0.677755</td>\n      <td>0.675219</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.677800</td>\n      <td>0.653785</td>\n      <td>0.758836</td>\n      <td>0.761052</td>\n      <td>0.758836</td>\n      <td>0.759615</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.646700</td>\n      <td>0.637106</td>\n      <td>0.787942</td>\n      <td>0.803114</td>\n      <td>0.787942</td>\n      <td>0.789532</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.639300</td>\n      <td>0.627797</td>\n      <td>0.787942</td>\n      <td>0.795294</td>\n      <td>0.787942</td>\n      <td>0.789319</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.630000</td>\n      <td>0.622600</td>\n      <td>0.792100</td>\n      <td>0.792177</td>\n      <td>0.792100</td>\n      <td>0.788876</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.618700</td>\n      <td>0.614457</td>\n      <td>0.790021</td>\n      <td>0.794073</td>\n      <td>0.790021</td>\n      <td>0.791059</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.612900</td>\n      <td>0.610106</td>\n      <td>0.781705</td>\n      <td>0.809565</td>\n      <td>0.781705</td>\n      <td>0.782974</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.604100</td>\n      <td>0.598958</td>\n      <td>0.804574</td>\n      <td>0.803896</td>\n      <td>0.804574</td>\n      <td>0.804107</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.596700</td>\n      <td>0.597016</td>\n      <td>0.800416</td>\n      <td>0.799463</td>\n      <td>0.800416</td>\n      <td>0.798775</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.586700</td>\n      <td>0.585164</td>\n      <td>0.819127</td>\n      <td>0.820330</td>\n      <td>0.819127</td>\n      <td>0.819553</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.590200</td>\n      <td>0.579679</td>\n      <td>0.823285</td>\n      <td>0.822943</td>\n      <td>0.823285</td>\n      <td>0.823081</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.577600</td>\n      <td>0.576848</td>\n      <td>0.825364</td>\n      <td>0.825128</td>\n      <td>0.825364</td>\n      <td>0.825231</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.575600</td>\n      <td>0.577187</td>\n      <td>0.814969</td>\n      <td>0.818225</td>\n      <td>0.814969</td>\n      <td>0.815801</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.574000</td>\n      <td>0.576378</td>\n      <td>0.817048</td>\n      <td>0.818476</td>\n      <td>0.817048</td>\n      <td>0.817534</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.566900</td>\n      <td>0.575097</td>\n      <td>0.817048</td>\n      <td>0.817676</td>\n      <td>0.817048</td>\n      <td>0.817305</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.568700</td>\n      <td>0.574978</td>\n      <td>0.810811</td>\n      <td>0.812050</td>\n      <td>0.810811</td>\n      <td>0.811257</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.563900</td>\n      <td>0.573672</td>\n      <td>0.817048</td>\n      <td>0.818941</td>\n      <td>0.817048</td>\n      <td>0.817639</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.563300</td>\n      <td>0.573543</td>\n      <td>0.814969</td>\n      <td>0.815428</td>\n      <td>0.814969</td>\n      <td>0.815166</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.563100</td>\n      <td>0.573030</td>\n      <td>0.817048</td>\n      <td>0.817340</td>\n      <td>0.817048</td>\n      <td>0.817180</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.561700</td>\n      <td>0.573075</td>\n      <td>0.817048</td>\n      <td>0.817340</td>\n      <td>0.817048</td>\n      <td>0.817180</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Could not locate the best model at /kaggle/working/results/adapter_2/checkpoint-2584/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2720, training_loss=0.5988502491922939, metrics={'train_runtime': 853.8898, 'train_samples_per_second': 101.301, 'train_steps_per_second': 3.185, 'total_flos': 6316911924480000.0, 'train_loss': 0.5988502491922939, 'epoch': 20.0})"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/hinglish-hate-task-2/test.csv\")\nX = test_df.data.values\ny = test_df.label.values\ntest_dataset = MyDataset(X, y, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:35:38.448626Z","iopub.execute_input":"2025-06-11T09:35:38.449170Z","iopub.status.idle":"2025-06-11T09:35:38.462801Z","shell.execute_reply.started":"2025-06-11T09:35:38.449145Z","shell.execute_reply":"2025-06-11T09:35:38.462047Z"}},"outputs":[{"name":"stdout","text":"Encoder has the following classes: ['hate' 'non-hate']\nThe new data type for y is <class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"trainer.predict(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:30:43.965224Z","iopub.execute_input":"2025-06-11T08:30:43.965491Z","iopub.status.idle":"2025-06-11T08:30:48.653187Z","shell.execute_reply.started":"2025-06-11T08:30:43.965473Z","shell.execute_reply":"2025-06-11T08:30:48.652293Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[ 0.24458964, -0.24023998],\n       [-0.20946077,  0.2403012 ],\n       [-0.20823666,  0.2399553 ],\n       ...,\n       [-0.21001852,  0.24005468],\n       [-0.20890388,  0.23997977],\n       [ 0.24473189, -0.24077846]], dtype=float32), label_ids=array([0, 1, 1, ..., 0, 0, 0]), metrics={'test_loss': 0.5735505223274231, 'test_accuracy': 0.8161397670549085, 'test_precision': 0.8163474785365424, 'test_recall': 0.8161397670549085, 'test_f1': 0.8162294088548435, 'test_runtime': 4.6781, 'test_samples_per_second': 256.942, 'test_steps_per_second': 8.123})"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"model.base_model.set_adapter(['hinglish_hate_1', 'hinglish_hate_2'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:43:07.444350Z","iopub.execute_input":"2025-06-11T08:43:07.444610Z","iopub.status.idle":"2025-06-11T08:43:07.449951Z","shell.execute_reply.started":"2025-06-11T08:43:07.444592Z","shell.execute_reply":"2025-06-11T08:43:07.449264Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/hinglish-hate/test-task1.csv\")\nX = test_df.data.values\ny = test_df.label.values\ntest_dataset = MyDataset(X, y, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:36:34.609357Z","iopub.execute_input":"2025-06-11T09:36:34.610043Z","iopub.status.idle":"2025-06-11T09:36:34.624586Z","shell.execute_reply.started":"2025-06-11T09:36:34.610018Z","shell.execute_reply":"2025-06-11T09:36:34.623880Z"}},"outputs":[{"name":"stdout","text":"Encoder has the following classes: ['hate' 'non-hate']\nThe new data type for y is <class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":121},{"cell_type":"code","source":"trainer.predict(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:43:56.512525Z","iopub.execute_input":"2025-06-11T08:43:56.512806Z","iopub.status.idle":"2025-06-11T08:44:02.442509Z","shell.execute_reply.started":"2025-06-11T08:43:56.512785Z","shell.execute_reply":"2025-06-11T08:44:02.441900Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[-0.19778466,  0.22222993],\n       [-0.20312594,  0.229599  ],\n       [-0.19992775,  0.22588298],\n       ...,\n       [-0.199821  ,  0.22575593],\n       [ 0.21515879, -0.20615792],\n       [ 0.21106333, -0.20119008]], dtype=float32), label_ids=array([1, 0, 1, ..., 1, 0, 0]), metrics={'test_loss': 0.6248688697814941, 'test_accuracy': 0.7311220889202541, 'test_precision': 0.7237488869488463, 'test_recall': 0.7311220889202541, 'test_f1': 0.7227431452317656, 'test_runtime': 5.9209, 'test_samples_per_second': 239.324, 'test_steps_per_second': 7.6})"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"output = \"/kaggle/working/muril_bert_adapters/\"\nmodel.save_pretrained(output)\ntokenizer.save_pretrained(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:46:35.043031Z","iopub.execute_input":"2025-06-11T08:46:35.043277Z","iopub.status.idle":"2025-06-11T08:46:35.762309Z","shell.execute_reply.started":"2025-06-11T08:46:35.043262Z","shell.execute_reply":"2025-06-11T08:46:35.761703Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/muril_bert_adapters/tokenizer_config.json',\n '/kaggle/working/muril_bert_adapters/special_tokens_map.json',\n '/kaggle/working/muril_bert_adapters/vocab.txt',\n '/kaggle/working/muril_bert_adapters/added_tokens.json',\n '/kaggle/working/muril_bert_adapters/tokenizer.json')"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"from peft import PeftConfig\n\nmuril_model = \"/kaggle/input/muril_classifier/pytorch/default/1\"\nhinglish_hate_1 = \"/kaggle/working/muril_bert_adapters/hinglish_hate_1\"\nhinglish_hate_2 = \"/kaggle/working/muril_bert_adapters/hinglish_hate_2\"\n\nbase_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, output_hidden_states=False)\n\npeft_model = PeftModelForSequenceClassification.from_pretrained(base_model, hinglish_hate_1, num_labels=2)\npeft_model.load_adapter(hinglish_hate_1, adapter_name=\"hinglish_hate_1\")\npeft_model.load_adapter(hinglish_hate_2, adapter_name='hinglish_hate_2')\n\n#peft_model.set_adapter(\"hinglish_hate_2\")\npeft_model.base_model.set_adapter([\"hinglish_hate_1\", \"hinglish_hate_2\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:34:48.952917Z","iopub.execute_input":"2025-06-11T09:34:48.953651Z","iopub.status.idle":"2025-06-11T09:34:50.785574Z","shell.execute_reply.started":"2025-06-11T09:34:48.953628Z","shell.execute_reply":"2025-06-11T09:34:50.784782Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":115},{"cell_type":"code","source":"new_trainer = ClassificationTrainer(\n    model=peft_model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    optimizers=(optimizer, scheduler),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:36:16.642294Z","iopub.execute_input":"2025-06-11T09:36:16.642553Z","iopub.status.idle":"2025-06-11T09:36:16.962177Z","shell.execute_reply.started":"2025-06-11T09:36:16.642537Z","shell.execute_reply":"2025-06-11T09:36:16.961590Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"#peft_model.base_model.set_adapter(\"hinglish_hate_2\")\nnew_trainer = ClassificationTrainer(\n    model=peft_model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    optimizers=(optimizer, scheduler),\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\nnew_trainer.predict(test_dataset) # Task 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:32:39.276011Z","iopub.execute_input":"2025-06-11T09:32:39.276286Z","iopub.status.idle":"2025-06-11T09:32:52.094942Z","shell.execute_reply.started":"2025-06-11T09:32:39.276268Z","shell.execute_reply":"2025-06-11T09:32:52.094184Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[ 0.11254247, -0.06880226],\n       [-0.15410027,  0.20360343],\n       [-0.15202044,  0.20362139],\n       ...,\n       [-0.1563042 ,  0.20506175],\n       [-0.17010796,  0.24416836],\n       [ 0.08897122, -0.04002063]], dtype=float32), label_ids=array([0, 1, 1, ..., 0, 0, 0]), metrics={'test_loss': 0.6264745593070984, 'test_model_preparation_time': 0.0055, 'test_accuracy': 0.800332778702163, 'test_precision': 0.8034933340167373, 'test_recall': 0.800332778702163, 'test_f1': 0.7974021787007133, 'test_runtime': 4.6899, 'test_samples_per_second': 256.297, 'test_steps_per_second': 8.103})"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"new_trainer.predict(test_dataset) # Task 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:33:33.693399Z","iopub.execute_input":"2025-06-11T09:33:33.693963Z","iopub.status.idle":"2025-06-11T09:33:39.208058Z","shell.execute_reply.started":"2025-06-11T09:33:33.693944Z","shell.execute_reply":"2025-06-11T09:33:39.207337Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[-0.1522802 ,  0.18991649],\n       [-0.148069  ,  0.1983913 ],\n       [-0.14530145,  0.18925565],\n       ...,\n       [-0.15332216,  0.20294136],\n       [ 0.11365376, -0.06761795],\n       [ 0.10139805, -0.0549578 ]], dtype=float32), label_ids=array([1, 0, 1, ..., 1, 0, 0]), metrics={'test_loss': 0.6552545428276062, 'test_model_preparation_time': 0.0055, 'test_accuracy': 0.7247706422018348, 'test_precision': 0.736249792641435, 'test_recall': 0.7247706422018348, 'test_f1': 0.6898122815696602, 'test_runtime': 5.5008, 'test_samples_per_second': 257.599, 'test_steps_per_second': 8.181})"},"metadata":{}}],"execution_count":114},{"cell_type":"code","source":"new_trainer.predict(test_dataset) # Task 1 with adapter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:36:38.905974Z","iopub.execute_input":"2025-06-11T09:36:38.906436Z","iopub.status.idle":"2025-06-11T09:36:44.835407Z","shell.execute_reply.started":"2025-06-11T09:36:38.906417Z","shell.execute_reply":"2025-06-11T09:36:44.834891Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[-0.54628086,  0.5706933 ],\n       [-0.54292077,  0.5693583 ],\n       [-0.5469816 ,  0.57290226],\n       ...,\n       [-0.5471181 ,  0.5730184 ],\n       [ 0.6275594 , -0.6185687 ],\n       [ 0.6197144 , -0.60985243]], dtype=float32), label_ids=array([1, 0, 1, ..., 1, 0, 0]), metrics={'test_loss': 0.5989140868186951, 'test_model_preparation_time': 0.0076, 'test_accuracy': 0.7311220889202541, 'test_precision': 0.7237850086407459, 'test_recall': 0.7311220889202541, 'test_f1': 0.7229389964481092, 'test_runtime': 5.9132, 'test_samples_per_second': 239.635, 'test_steps_per_second': 7.61})"},"metadata":{}}],"execution_count":122},{"cell_type":"code","source":"new_trainer.predict(test_dataset) # Task 2 with adapter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:36:20.975103Z","iopub.execute_input":"2025-06-11T09:36:20.975592Z","iopub.status.idle":"2025-06-11T09:36:26.049975Z","shell.execute_reply.started":"2025-06-11T09:36:20.975569Z","shell.execute_reply":"2025-06-11T09:36:26.049249Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"PredictionOutput(predictions=array([[ 0.62307155, -0.61346555],\n       [-0.53667545,  0.5602557 ],\n       [-0.5402038 ,  0.5646883 ],\n       ...,\n       [-0.53787404,  0.56118286],\n       [-0.5273331 ,  0.5574368 ],\n       [ 0.6257093 , -0.61647457]], dtype=float32), label_ids=array([0, 1, 1, ..., 0, 0, 0]), metrics={'test_loss': 0.5297549962997437, 'test_model_preparation_time': 0.0076, 'test_accuracy': 0.7662229617304492, 'test_precision': 0.7814071614726438, 'test_recall': 0.7662229617304492, 'test_f1': 0.7667628969106643, 'test_runtime': 5.0574, 'test_samples_per_second': 237.669, 'test_steps_per_second': 7.514})"},"metadata":{}}],"execution_count":120}]}