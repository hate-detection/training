{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f2c8c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup, AutoModel\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "import os\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d325250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/muril-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                           num_labels=2,\n",
    "                                                           output_hidden_states=True)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3916637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(y):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    print(f\"Encoder has the following classes: {encoder.classes_}\")\n",
    "    print(f\"The new data type for y is {type(y)}\")\n",
    "\n",
    "    return y\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def get_TP_FP_FN(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    TP = np.sum((pred_flat == 1) & (labels_flat == 1))\n",
    "    FP = np.sum((pred_flat == 1) & (labels_flat == 0))\n",
    "    FN = np.sum((pred_flat == 0) & (labels_flat == 1))\n",
    "\n",
    "    return {'TP': TP,\n",
    "            'FP': FP,\n",
    "            'FN': FN}\n",
    "\n",
    "\n",
    "def precision(TP, FP):\n",
    "    if TP + FP == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return TP / (TP + FP)\n",
    "\n",
    "\n",
    "def recall(TP, FN):\n",
    "    if TP + FN == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return TP / (TP + FN)\n",
    "\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc07de5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non-hate</td>\n",
       "      <td>nice buro yes i am हुसैन खान is me happy owesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate</td>\n",
       "      <td>भवन k लोडे कटुए काट k फेंक देंगे बहनचोद तुझे सुअर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>ye india के सारे मुसलमान बाबर or अकबर की नागरा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate</td>\n",
       "      <td>भाई इनकी मां चोद do मील को आहा b मिले हिन्दू म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hate</td>\n",
       "      <td>गलती हो गई बाबा साहब अंबेडकर se तुन जैसे lunf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               data\n",
       "0  non-hate  nice buro yes i am हुसैन खान is me happy owesi...\n",
       "1      hate  भवन k लोडे कटुए काट k फेंक देंगे बहनचोद तुझे सुअर\n",
       "2      hate  ye india के सारे मुसलमान बाबर or अकबर की नागरा...\n",
       "3      hate  भाई इनकी मां चोद do मील को आहा b मिले हिन्दू म...\n",
       "4      hate  गलती हो गई बाबा साहब अंबेडकर se तुन जैसे lunf ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/hate-dataset.csv\")\n",
    "df = df.drop(['text'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9e5894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder has the following classes: ['hate' 'non-hate']\n",
      "The new data type for y is <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  nice buro yes i am हुसैन खान is me happy owesi brothers and cold and my friend is all is well with your video\n",
      "Token IDs: tensor([   104,  19634,    173,  55696,  29768,    180,   3516,  26436,   3907,\n",
      "          1121,   1868,   9971,    186, 107972,   1206,  19412,   1111,  15756,\n",
      "          1111,   1725,   8462,   1121,   1375,   1121,   1999,   1147,   1427,\n",
      "          3080,    105,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])\n",
      "Label: tensor(1)\n"
     ]
    }
   ],
   "source": [
    "X = df.data.values\n",
    "y = df.label.values\n",
    "\n",
    "y = encode_label(y)\n",
    "\n",
    "class_weight = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight = torch.tensor(class_weight, dtype=torch.float)\n",
    "class_weight = class_weight.to(device)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# convert the sentences into tokens for MuRIL\n",
    "# pre-processing, append input_ids and\n",
    "# attention_masks into a list\n",
    "for sentence in X:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                                        sentence,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=128,\n",
    "                                        padding='max_length',\n",
    "                                        truncation=True,\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "\n",
    "# convert the lists into tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(y)\n",
    "\n",
    "# print a visualisation\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Label:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2dfe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22672 training samples\n",
      "5668 validation samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"{train_size} training samples\")\n",
    "print(f\"{val_size} validation samples\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "                train_dataset,\n",
    "                sampler = RandomSampler(train_dataset),\n",
    "                batch_size = batch_size\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "                val_dataset,\n",
    "                sampler = SequentialSampler(val_dataset),\n",
    "                batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff4ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                lr = 2e-5,\n",
    "                eps = 1e-8\n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3d6891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch    40  of    709.\tElapsed: 0:00:14.\n",
      "\tBatch    80  of    709.\tElapsed: 0:00:28.\n",
      "\tBatch   120  of    709.\tElapsed: 0:00:42.\n",
      "\tBatch   160  of    709.\tElapsed: 0:00:56.\n",
      "\tBatch   200  of    709.\tElapsed: 0:01:10.\n",
      "\tBatch   240  of    709.\tElapsed: 0:01:24.\n",
      "\tBatch   280  of    709.\tElapsed: 0:01:39.\n",
      "\tBatch   320  of    709.\tElapsed: 0:01:53.\n",
      "\tBatch   360  of    709.\tElapsed: 0:02:07.\n",
      "\tBatch   400  of    709.\tElapsed: 0:02:21.\n",
      "\tBatch   440  of    709.\tElapsed: 0:02:35.\n",
      "\tBatch   480  of    709.\tElapsed: 0:02:49.\n",
      "\tBatch   520  of    709.\tElapsed: 0:03:04.\n",
      "\tBatch   560  of    709.\tElapsed: 0:03:18.\n",
      "\tBatch   600  of    709.\tElapsed: 0:03:32.\n",
      "\tBatch   640  of    709.\tElapsed: 0:03:46.\n",
      "\tBatch   680  of    709.\tElapsed: 0:04:00.\n",
      "\n",
      "Average training loss: 0.60\n",
      "\n",
      "Training epoch took: 0:04:10\n",
      "\n",
      "Running validation...\n",
      "\tAccuracy: 0.76\n",
      "\n",
      "Validation Loss: 0.53\n",
      "\n",
      "Validation took: 0:00:19\n",
      "\n",
      "Precision: 0.81\n",
      "Recall: 0.80\n",
      "F1 Score: 0.80\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\tBatch    40  of    709.\tElapsed: 0:00:14.\n",
      "\tBatch    80  of    709.\tElapsed: 0:00:28.\n",
      "\tBatch   120  of    709.\tElapsed: 0:00:42.\n",
      "\tBatch   160  of    709.\tElapsed: 0:00:56.\n",
      "\tBatch   200  of    709.\tElapsed: 0:01:10.\n",
      "\tBatch   240  of    709.\tElapsed: 0:01:24.\n",
      "\tBatch   280  of    709.\tElapsed: 0:01:39.\n",
      "\tBatch   320  of    709.\tElapsed: 0:01:53.\n",
      "\tBatch   360  of    709.\tElapsed: 0:02:07.\n",
      "\tBatch   400  of    709.\tElapsed: 0:02:22.\n",
      "\tBatch   440  of    709.\tElapsed: 0:02:36.\n",
      "\tBatch   480  of    709.\tElapsed: 0:02:50.\n",
      "\tBatch   520  of    709.\tElapsed: 0:03:04.\n",
      "\tBatch   560  of    709.\tElapsed: 0:03:18.\n",
      "\tBatch   600  of    709.\tElapsed: 0:03:32.\n",
      "\tBatch   640  of    709.\tElapsed: 0:03:46.\n",
      "\tBatch   680  of    709.\tElapsed: 0:04:00.\n",
      "\n",
      "Average training loss: 0.47\n",
      "\n",
      "Training epoch took: 0:04:10\n",
      "\n",
      "Running validation...\n",
      "\tAccuracy: 0.76\n",
      "\n",
      "Validation Loss: 0.51\n",
      "\n",
      "Validation took: 0:00:20\n",
      "\n",
      "Precision: 0.84\n",
      "Recall: 0.74\n",
      "F1 Score: 0.79\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\tBatch    40  of    709.\tElapsed: 0:00:14.\n",
      "\tBatch    80  of    709.\tElapsed: 0:00:28.\n",
      "\tBatch   120  of    709.\tElapsed: 0:00:42.\n",
      "\tBatch   160  of    709.\tElapsed: 0:00:56.\n",
      "\tBatch   200  of    709.\tElapsed: 0:01:10.\n",
      "\tBatch   240  of    709.\tElapsed: 0:01:24.\n",
      "\tBatch   280  of    709.\tElapsed: 0:01:39.\n",
      "\tBatch   320  of    709.\tElapsed: 0:01:53.\n",
      "\tBatch   360  of    709.\tElapsed: 0:02:07.\n",
      "\tBatch   400  of    709.\tElapsed: 0:02:21.\n",
      "\tBatch   440  of    709.\tElapsed: 0:02:35.\n",
      "\tBatch   480  of    709.\tElapsed: 0:02:48.\n",
      "\tBatch   520  of    709.\tElapsed: 0:03:02.\n",
      "\tBatch   560  of    709.\tElapsed: 0:03:15.\n",
      "\tBatch   600  of    709.\tElapsed: 0:03:29.\n",
      "\tBatch   640  of    709.\tElapsed: 0:03:43.\n",
      "\tBatch   680  of    709.\tElapsed: 0:03:57.\n",
      "\n",
      "Average training loss: 0.38\n",
      "\n",
      "Training epoch took: 0:04:07\n",
      "\n",
      "Running validation...\n",
      "\tAccuracy: 0.77\n",
      "\n",
      "Validation Loss: 0.54\n",
      "\n",
      "Validation took: 0:00:20\n",
      "\n",
      "Precision: 0.85\n",
      "Recall: 0.75\n",
      "F1 Score: 0.80\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:13:26 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "total_t0 = time.time()\n",
    "\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(f'\\n======== Epoch {epoch_i + 1} / {epochs} ========')\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            print('\\tBatch {:>5,}  of  {:>5,}.\\tElapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "\n",
    "        outputs = model(b_input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels)\n",
    "\n",
    "        #loss = outputs.loss\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weight, reduction='mean')\n",
    "        \n",
    "        loss = criterion(outputs.logits, b_labels)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\\nAverage training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"\\nTraining epoch took: {:}\".format(training_time))\n",
    "\n",
    "\n",
    "    print(\"\\nRunning validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    total_prec = 0\n",
    "    total_rec = 0\n",
    "\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    f1_val = 0\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids,\n",
    "                                token_type_ids=None,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weight, reduction='mean')\n",
    "\n",
    "            loss = criterion(outputs.logits, b_labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "        counts = get_TP_FP_FN(logits, label_ids)\n",
    "\n",
    "        TP = counts['TP']\n",
    "        FP = counts['FP']\n",
    "        FN = counts['FN']\n",
    "\n",
    "        total_prec += precision(TP, FP)\n",
    "        total_rec += recall(TP, FN)\n",
    "\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"\\tAccuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\\nValidation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"\\nValidation took: {:}\".format(validation_time))\n",
    "\n",
    "\n",
    "    prec = total_prec / len(validation_dataloader)\n",
    "    rec = total_rec / len(validation_dataloader)\n",
    "    f1_val = f1_score(prec, rec)\n",
    "\n",
    "    print(\"\\nPrecision: {0:.2f}\".format(prec))\n",
    "    print(\"Recall: {0:.2f}\".format(rec))\n",
    "    print(\"F1 Score: {0:.2f}\".format(f1_val))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1 Score': f1_val,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6298dfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model_save/tokenizer_config.json',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/vocab.txt',\n",
       " './model_save/added_tokens.json',\n",
       " './model_save/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./model_save/\"\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "args = {\"learning_rate\": 2e-5, \n",
    "        \"adam_epsilon\": 1e-8}\n",
    "\n",
    "torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9097ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./model_save/\"\n",
    "\n",
    "muril_model = AutoModelForSequenceClassification.from_pretrained(output_dir, num_labels=2, output_hidden_states=False, output_attentions=False)\n",
    "tokenizer_model = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "muril_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b84b82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent = \"चूड़ियां पहन लो शर्म करो Baised ho तुम log मुल्लो pr एक action नहीं ले पाते संविधान की कसम खाते ho संविधान के रक्षक हो न की ममता या तृणमूल के इतनी चाटुकारिता सही नहीं\"\n",
    "\n",
    "sent = \"muslims have good jawline क्यूंकि उनका muslim होता है\"\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "encoded_dict = tokenizer_model.encode_plus(\n",
    "                                        sent,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=128,\n",
    "                                        padding='max_length',\n",
    "                                        truncation=True,\n",
    "                                        return_attention_mask=True,\n",
    "                                        return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_id = encoded_dict['input_ids']\n",
    "attention_mask = encoded_dict['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82f7913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muril_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = muril_model(input_id,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=attention_mask\n",
    "                    )\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "\n",
    "pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "pred_flat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
